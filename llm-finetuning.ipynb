{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # set up hub\n",
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 8.07k/8.07k [00:00<00:00, 22.9MB/s]\n",
      "Downloading data: 100%|██████████| 18.6M/18.6M [00:00<00:00, 74.5MB/s]\n",
      "Downloading data: 100%|██████████| 1.23M/1.23M [00:00<00:00, 24.3MB/s]\n",
      "Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 447115.81 examples/s]\n",
      "Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 540925.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset('ag_news')\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 296531.28 examples/s]\n",
      "Filter: 100%|██████████| 7600/7600 [00:00<00:00, 276561.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_datasets = raw_datasets.filter(lambda example: example['label'] == 2)\n",
    "filtered_datasets = filtered_datasets.remove_columns('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = (tokenizer.eos_token)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 30000/30000 [00:03<00:00, 7955.06 examples/s] \n",
      "Map: 100%|██████████| 1900/1900 [00:00<00:00, 9559.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 1900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)\n",
    "\n",
    "tokenized_datasets = filtered_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=['text']\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: 37\n",
      "input_ids shape: 55\n",
      "input_ids shape: 51\n"
     ]
    }
   ],
   "source": [
    "samples = [tokenized_datasets['train'][i] for i in range(3)]\n",
    "\n",
    "for sample in samples:\n",
    "    print(f\"input_ids shape: {len(sample['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 55])\n",
      "attention_mask shape: torch.Size([3, 55])\n",
      "labels shape: torch.Size([3, 55])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator(samples)\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"sft_cml4\",\n",
    "    push_to_hub=True,\n",
    "    per_device_train_batch_size=3,\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(5000)),\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2777"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpwauyo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/wandb/run-20240617_105841-gft7rvdd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pwauyo/huggingface/runs/gft7rvdd' target=\"_blank\">unique-snowflake-18</a></strong> to <a href='https://wandb.ai/pwauyo/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pwauyo/huggingface' target=\"_blank\">https://wandb.ai/pwauyo/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pwauyo/huggingface/runs/gft7rvdd' target=\"_blank\">https://wandb.ai/pwauyo/huggingface/runs/gft7rvdd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3334' max='3334' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3334/3334 36:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.182200</td>\n",
       "      <td>3.988030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.900900</td>\n",
       "      <td>3.924780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.784600</td>\n",
       "      <td>3.932813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.709500</td>\n",
       "      <td>3.839306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.504300</td>\n",
       "      <td>3.813025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.482600</td>\n",
       "      <td>3.760766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.351100</td>\n",
       "      <td>3.699686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.324300</td>\n",
       "      <td>3.634866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.523500</td>\n",
       "      <td>3.782559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.075800</td>\n",
       "      <td>3.762716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.093200</td>\n",
       "      <td>3.723280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.996200</td>\n",
       "      <td>3.705880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.007200</td>\n",
       "      <td>3.675647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.964200</td>\n",
       "      <td>3.680060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.906200</td>\n",
       "      <td>3.665820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.927900</td>\n",
       "      <td>3.661061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3334, training_loss=2.821503454436066, metrics={'train_runtime': 2213.6817, 'train_samples_per_second': 4.517, 'train_steps_per_second': 1.506, 'total_flos': 366881060736000.0, 'train_loss': 2.821503454436066, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 498M/498M [00:09<00:00, 53.2MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/pbwauyo/sft_cml4/commit/1c770e93233ecd057902367244166d087228d79b', commit_message='End of training', commit_description='', oid='1c770e93233ecd057902367244166d087228d79b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Profit Narrows, Outlook Trails Estimates  CHICAGO (Reuters) - Q2 profit grew more than expected, driven by  stronger earnings in technology and a  narrower-than-expected reading in gasoline prices, the University of \n",
      "\n",
      "Wall Street sees rise in third quarter Profit London lifted by a rise in US gasoline prices, and Wall Street sees a rebound.   NEW YORK (Reuters) - Investors will watch for news from  Russia, Iraq and Wall Street on Thursday, after \n",
      "\n",
      "Google IPO begins public Google surged today on the eve of the most anticipated IPO in tech history. The stock #39;s deal with Google Inc. will raise \\$1.67 billion, or nearly \\$1.67 billion, over its \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model='pbwauyo/sft_cml4', device=device)\n",
    "pipe.tokenizer.pad_token_id = 50256\n",
    "\n",
    "print(pipe(\"Q1\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"], '\\n')\n",
    "print(pipe(\"Wall\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"], '\\n')\n",
    "print(pipe(\"Google\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
